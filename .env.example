# LLM Configuration (supports multiple providers)
LLM_PROVIDER=openai  # openai, deepseek, qwen, groq, together, perplexity, openrouter, ollama, anthropic, local
LLM_API_KEY=your_llm_api_key_here
LLM_BASE_URL=  # Optional: custom endpoint (e.g., http://localhost:11434/v1 for Ollama)
LLM_MODEL=gpt-3.5-turbo  # Model name (e.g., deepseek-chat, qwen-turbo, llama2, claude-3-sonnet)
LLM_MAX_TOKENS=2000
LLM_TEMPERATURE=0.1

# Legacy OpenAI support (backwards compatibility)
# OPENAI_API_KEY=your_openai_api_key_here

# Database Configuration
DATABASE_URL=postgresql://username:password@localhost:5432/automation_agent
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=automation_agent
DATABASE_USER=username
DATABASE_PASSWORD=password

# Application Configuration
SECRET_KEY=your_secret_key_here_minimum_32_chars
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Slack OAuth2 Configuration
SLACK_CLIENT_ID=your_slack_client_id
SLACK_CLIENT_SECRET=your_slack_client_secret
SLACK_REDIRECT_URI=http://localhost:8000/auth/slack/callback

# Jira OAuth2 Configuration
JIRA_CLIENT_ID=your_jira_client_id
JIRA_CLIENT_SECRET=your_jira_client_secret
JIRA_REDIRECT_URI=http://localhost:8000/auth/jira/callback
JIRA_BASE_URL=https://your-domain.atlassian.net

# AWS Configuration
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
AWS_S3_BUCKET=your-s3-bucket-name

# GitHub OAuth2 Configuration (Additional API)
GITHUB_CLIENT_ID=your_github_client_id
GITHUB_CLIENT_SECRET=your_github_client_secret
GITHUB_REDIRECT_URI=http://localhost:8000/auth/github/callback

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json 